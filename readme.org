#+title: Puddle: A Neuromorphic Liquid State Machine Framework for Multi-Objective Optimization
#+authors: Jackson Mowry & Chris White

* Running the Classify App
1. Run =make=
2. Calculate an optimal reservoir for your dataset
#+begin_src shell
$ bash scripts/generate_best_reservoir.bash
Usage: scripts/generate_best_reservoir.bash [options] <data_directory>
Options:
  -s <size>                    Reservoir size
  -p <connection_probability>  Connection probability
  -c <class_neurons>           Number of class neurons
  -o <output_weight>           Output weight
  -b <num_bins>                Number of bins
  -n <num_tests>               Number of reservoirs to generate (default: 10)


$ bash scripts/generate_best_reservoir.bash -s 250 -p 0.025 -c 64 -b 10 -n 100 datasets/quadrant_small/
Generating Reservoir 100/100

Best seed: 13714

Smallest Deltas:
Class 0: 0.896244
Class 1: 1.212823
Class 2: 1.257205
Class 3: 1.331437

$
#+end_src
- The "Best seed" is a reproducible seed that allows you to regenerate your reservoir at anytime, in addition to it being saved in =best_reservoir.json=
- The "Smallest Deltas" block shows you the results from the best network.
  - These deltas represent the average angle between vectors in the specified class and the closest other class
  - The intuition behind this is that the densely connected layer that reads this reservoir will have a much easier time separating classes if they're in distinct regions of the high dimensional space
3. Perform a training run with your new reservoir
#+begin_src shell
$ bash scripts/run_example.bash -e 1000000 -b 10 -r 0.0025 datasets/quadrant_small/
Epoch 0:
...
Batch: 100/100 Accuracy: 1.00, Loss: 0.01
Epoch 999999:
Batch: 100/100
CONFUSION MATRIX:
 258    0    0    0
   0  269    0    0
   0    0  219    0
   0    0    0  254

 Accuracy: 1.00, Loss: 0.01
Final weight matrix:
10.121 -30.783 -76.463 -18.659 49.457 48.287 -62.864 -63.314 -13.356 -39.199  7.971 -47.203 -28.749 -104.364  7.831  4.184 27.514 -60.626 25.306 -19.973 -12.309 47.517 31.380 -61.547 25.756 -12.540 -49.960 -23.066 49.076 -64.095 -68.445 59.845 -6.699 -26.131 -23.421  7.285 -51.326 -36.145 26.379 -20.097 11.283 44.256 -86.702 -60.656 16.086 -62.139 -1.759 -2.413 -14.111 -94.968 108.362  4.347 -17.404 -14.881 -41.473 -35.100 29.637 87.872 18.252 29.812 -14.797 60.477  1.815 -24.664 -31.639
-10.240 53.391 -24.364 -59.707 22.618  5.860 39.360  6.661 -145.254 -41.860 -38.428 -84.918 -26.311 108.832 -13.966 10.935 -60.509 -17.485 -11.770 78.983 -28.893 52.713 35.867 15.248 -17.435 13.763 64.827 41.273 -16.068 23.082 14.730 -13.561 45.523 13.584 70.694 33.860 82.467 77.053 43.098 -28.287 60.545 -13.967 31.284 -37.770  0.898 14.947 61.346 18.643 38.348 -6.869 -60.099 -6.964 28.940 21.845 -28.018 -85.450 102.059 -46.039 38.561 -2.753 39.737 37.247 34.727 17.409 -37.748
 4.807 15.448 44.019 -6.411 24.350 -6.748 -26.925 -19.428 96.162 54.969 25.677 53.085 10.144 -53.884 -17.587 -12.179 57.535 60.904 -51.609 -99.535 82.225 -84.019  0.619  0.728  8.061 14.711 -2.246 -25.754 -47.364 -10.721 10.227 -28.159 -66.185 20.544 -21.617 -60.633 -62.421 -50.444 -79.267 24.755 -16.035 24.743 -10.031 59.216 27.830 -88.535 -28.559  9.578 -36.220 41.584 61.544 13.329 -27.051 -15.712 -13.688 92.507 -48.985 -7.626 12.508 -10.555 13.973 -35.335  4.804 24.294 68.907
-0.085 -44.025 54.555 81.375 -91.753 -42.175 45.946 71.012 64.164 25.858  3.880 74.546 44.724 51.252 29.364 -11.471 -19.853 24.621 36.902 36.791 -41.452 -11.000 -66.418 43.564 -14.095 -15.988 -21.289  0.321 17.881 50.069 51.937 -11.167 25.114 -5.433 -26.897 19.126 31.548 10.239  5.676 21.052 -53.697 -55.685 69.598 39.070 -46.046 131.972 -28.707 -33.321  5.449 59.564 -108.673 -1.228 11.148  7.241 84.951 25.891 -88.165 -29.194 -60.016 -9.216 -38.432 -61.772 -47.709 -18.266  1.031
#+end_src
